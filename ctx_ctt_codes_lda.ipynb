{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "utils/model_helper.py:30: UserWarning: If you are using Attention model, plz use Theano as the backend of keras. Because the dot function of Tensorflow backend does not work.\n",
      "  'If you are using Attention model, plz use Theano as the backend of keras. Because the dot function of Tensorflow backend does not work.')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This script is to test whether integrating lda works or not\n",
    "Thus, this model is to start with the simplest model.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from gensim.corpora import Dictionary\n",
    "from utils import lda_helper, data_helper, model_helper\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout, GRU, Bidirectional\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# parameters for initial configuration\n",
    "config = data_helper.BaseConfiguration()\n",
    "config.MAX_SENTS = 10\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing dataset\n",
      "Train Length: 17952\n",
      "Valid Length: 2244\n",
      "Test Length: 2244\n",
      "Overall MI Code Distribution: Counter({0: 10739, 1: 7796, -1: 3906})\n",
      "Training MI Code Distribution: Counter({0: 8575, 1: 6246, -1: 3131})\n",
      "Validation MI Code Distribution: Counter({0: 1069, 1: 787, -1: 388})\n",
      "Testing MI Code Distribution: Counter({0: 1095, 1: 762, -1: 387})\n"
     ]
    }
   ],
   "source": [
    "print('preparing dataset')\n",
    "\"\"\"preprare dataset \"\"\"\n",
    "dataset_path = './preprocessed_data/dataset.pkl'\n",
    "data_whole = pickle.load(open(dataset_path, 'rb'))\n",
    "labels = data_whole['labels']\n",
    "codes = data_whole['codes']\n",
    "\n",
    "processed_dataset = data_whole['dataset_processed']\n",
    "processed_contexts = data_whole['context_processed']\n",
    "processed_labels = data_whole['labels_preprocessed']\n",
    "code_targets = data_whole['codes_preprocessed']\n",
    "train_indices = data_whole['train_indices']\n",
    "valid_indices = data_whole['valid_indices']\n",
    "test_indices = data_whole['test_indices']\n",
    "keras_tokenizer = data_whole['keras_tokenizer']\n",
    "labels_tokenizer = data_whole['labels_tokenizer']\n",
    "\n",
    "# lda_tokenizer = Dictionary.load('./preprocessed_data/lda/lda_dict.pkl')\n",
    "# lda_model = lda_helper.load_lda('./preprocessed_data/lda/lda.model')\n",
    "# ctt_lda_idx = lda_helper.doc2idx(lda_tokenizer, data_whole['dataset_raw'], config.seq_max_len)\n",
    "# ctx_lda_idx = lda_helper.doc2idx(lda_tokenizer, data_whole['context_raw'], config.seq_max_len)\n",
    "# convert doc_raw to bags of words\n",
    "# doc_topics_ctt = lda_helper.doc2topics(lda_tokenizer, lda_model, data_whole['dataset_raw'])\n",
    "ctt_lda_idx = data_whole['ctt_lda_idx']\n",
    "ctx_lda_idx = data_whole['ctx_lda_idx']\n",
    "\n",
    "# get training data\n",
    "x_train = processed_dataset[train_indices]\n",
    "x_valid = processed_dataset[valid_indices]\n",
    "x_test = processed_dataset[test_indices]\n",
    "\n",
    "ctt_lda_train = ctt_lda_idx[train_indices]\n",
    "ctt_lda_valid = ctt_lda_idx[valid_indices]\n",
    "ctt_lda_test = ctt_lda_idx[test_indices]\n",
    "\n",
    "ctx_train = processed_contexts[train_indices]\n",
    "ctx_valid = processed_contexts[valid_indices]\n",
    "ctx_test = processed_contexts[test_indices]\n",
    "\n",
    "ctx_lda_train = ctx_lda_idx[train_indices]\n",
    "ctx_lda_valid = ctx_lda_idx[valid_indices]\n",
    "ctx_lda_test = ctx_lda_idx[test_indices]\n",
    "\n",
    "prev10_train = processed_labels[train_indices]\n",
    "prev10_valid = processed_labels[valid_indices]\n",
    "prev10_test = processed_labels[test_indices]\n",
    "\n",
    "# get labels\n",
    "code_train = code_targets[train_indices]\n",
    "code_valid = code_targets[valid_indices]\n",
    "code_test = code_targets[test_indices]\n",
    "\n",
    "print('Train Length: ' + str(len(train_indices)))\n",
    "print('Valid Length: ' + str(len(valid_indices)))\n",
    "print('Test Length: ' + str(len(test_indices)))\n",
    "print('Overall MI Code Distribution: ' + str(Counter(codes)))\n",
    "print('Training MI Code Distribution: ' + str(Counter(codes[train_indices])))\n",
    "print('Validation MI Code Distribution: ' + str(Counter(codes[valid_indices])))\n",
    "print('Testing MI Code Distribution: ' + str(Counter(codes[test_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Construct embedding layers\n",
    "\"\"\"\n",
    "print('Initialize weights')\n",
    "if not os.path.exists('./weights/w2v.npy'):\n",
    "    # load pretrained embeddings\n",
    "    w2v_path = './preprocessed_data/w2v_corpus/google.bin'\n",
    "    if 'glove' in w2v_path:\n",
    "        w2v_model = data_helper.load_glove(w2v_path)\n",
    "    else:\n",
    "        w2v_model = data_helper.load_word2vec(w2v_path)\n",
    "    config.embedding_size = len(w2v_model['the'])\n",
    "    # initialize weights\n",
    "    embd_weights = model_helper.init_weights(w2v_model, keras_tokenizer, config.embedding_size)\n",
    "    np.save('./weights/w2v.npy', embd_weights)\n",
    "else:\n",
    "    embd_weights = np.load('./weights/w2v.npy')\n",
    "\n",
    "if not os.path.exists('./weights/lda.npy'):\n",
    "    lda_weights = lda_helper.init_weight('./preprocessed_data/lda/lda.model', 20)\n",
    "    np.save('./weights/lda.npy', lda_weights)\n",
    "else:\n",
    "    lda_weights = np.load('./weights/lda.npy')\n",
    "\n",
    "if not os.path.exists('./weights/code_prevs.npy'):\n",
    "    import gensim\n",
    "    label2vec_model = gensim.models.Word2Vec.load('./preprocessed_data/w2v_corpus/w2v_codes_50.txt')\n",
    "    code_weights = np.zeros((len(labels_tokenizer.word_index) + 1, 50))\n",
    "    for label_tmp, i in labels_tokenizer.word_index.items():\n",
    "        # if word is found in the model, will be zeros\n",
    "        if label_tmp in label2vec_model.wv:\n",
    "            code_weights[i] = label2vec_model.wv.get_vector(label_tmp)\n",
    "    np.save('./weights/code_prevs.npy', code_weights)\n",
    "else:\n",
    "    code_weights = np.load('./weights/code_prevs.npy')\n",
    "\n",
    "ctt_embedding = model_helper.build_embedding(embd_weights, config.seq_max_len, name='ctt_embed')\n",
    "# initial weights for ctx embeddings\n",
    "ctx_embedding = model_helper.build_embedding(embd_weights, config.seq_max_len, name='ctx_embed')\n",
    "\n",
    "lda_weights = lda_helper.init_weight('./preprocessed_data/lda/lda.model', 20)\n",
    "lda_ctt_embed = lda_helper.build_embedding(lda_weights, config.seq_max_len, name='ctt_lda_embed')\n",
    "lda_ctx_embed = lda_helper.build_embedding(lda_weights, config.seq_max_len, name='ctx_lda_embed')\n",
    "\n",
    "code_embedding = model_helper.build_embedding(embd_weights, 10, name='code_embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "ctx_lda_input (InputLayer)       (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "ctt_lda_input (InputLayer)       (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "ctx_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "ctx_lda_embed (Embedding)        (None, 100, 20)       167400      ctx_lda_input[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "ctt_input (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "ctt_lda_embed (Embedding)        (None, 100, 20)       167400      ctt_lda_input[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "ctx_embed (Embedding)            (None, 100, 300)      2510100     ctx_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 100, 20)       80          ctx_lda_embed[2][0]              \n",
      "____________________________________________________________________________________________________\n",
      "ctt_embed (Embedding)            (None, 100, 300)      2510100     ctt_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 100, 20)       80          ctt_lda_embed[2][0]              \n",
      "____________________________________________________________________________________________________\n",
      "ctx_bilstm (Bidirectional)       (None, 200)           240600      ctx_embed[2][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lda_bilstm_ctx (Bidirectional)   (None, 40)            4920        batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "ctt_bilstm (Bidirectional)       (None, 200)           240600      ctt_embed[2][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lda_bilstm_ctt (Bidirectional)   (None, 40)            4920        batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 200)           0           ctx_bilstm[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 40)            0           lda_bilstm_ctx[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 200)           0           ctt_bilstm[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 40)            0           lda_bilstm_ctt[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)      (None, 240)           0           dropout_13[0][0]                 \n",
      "                                                                   dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)      (None, 240)           0           dropout_11[0][0]                 \n",
      "                                                                   dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "merged_dense_ctx (Dense)         (None, 100)           24100       concatenate_8[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "merged_dense_ctt (Dense)         (None, 100)           24100       concatenate_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)      (None, 200)           0           merged_dense_ctx[0][0]           \n",
      "                                                                   merged_dense_ctt[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 200)           0           concatenate_9[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "final_output (Dense)             (None, 3)             603         dropout_15[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 5,895,003\n",
      "Trainable params: 5,894,923\n",
      "Non-trainable params: 80\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 17952 samples, validate on 2244 samples\n",
      "Epoch 1/10\n",
      "17952/17952 [==============================] - 164s - loss: 0.8947 - acc: 0.5916 - val_loss: 0.8502 - val_acc: 0.6279\n",
      "Epoch 2/10\n",
      "17952/17952 [==============================] - 169s - loss: 0.7670 - acc: 0.6618 - val_loss: 0.7985 - val_acc: 0.6511\n",
      "Epoch 3/10\n",
      "11968/17952 [===================>..........] - ETA: 54s - loss: 0.6506 - acc: 0.7186"
     ]
    }
   ],
   "source": [
    "\"\"\"CTT\"\"\"\n",
    "# define layers for ctt\n",
    "ctt_input = Input(shape=(config.seq_max_len,), dtype='int32', name='ctt_input')\n",
    "ctt_embed = ctt_embedding(ctt_input)\n",
    "ctt_lstm = Bidirectional(GRU(100, recurrent_dropout=0.1, kernel_initializer=\"glorot_uniform\", recurrent_activation='tanh'),\n",
    "                                name='ctt_bilstm')(ctt_embed)\n",
    "ctt_dropout = Dropout(0.2)(ctt_lstm)\n",
    "\n",
    "# define layers for topic-word\n",
    "lda_input_ctt = Input(shape=(config.seq_max_len,), dtype='int32', name='ctt_lda_input')\n",
    "lda_embed_ctt = lda_ctt_embed(lda_input_ctt)\n",
    "lda_embed_norm_ctt = BatchNormalization()(lda_embed_ctt)\n",
    "lda_lstm_ctt = Bidirectional(GRU(20, recurrent_dropout=0.1, kernel_initializer=\"glorot_uniform\", recurrent_activation='tanh'),\n",
    "                                name='lda_bilstm_ctt')(lda_embed_norm_ctt)\n",
    "lda_dropout_ctt = Dropout(0.2)(lda_lstm_ctt)\n",
    "\n",
    "merged_vector_ctt = keras.layers.concatenate([ctt_dropout, lda_dropout_ctt], axis=-1)\n",
    "merged_dense_ctt = Dense(100, activation='relu',\n",
    "                     kernel_initializer=\"glorot_uniform\", name='merged_dense_ctt')(merged_vector_ctt)\n",
    "\n",
    "\"\"\"CTX\"\"\"\n",
    "# define layers for ctx\n",
    "ctx_input = Input(shape=(config.seq_max_len,), dtype='int32', name='ctx_input')\n",
    "ctx_embed = ctx_embedding(ctx_input)\n",
    "ctx_lstm = Bidirectional(GRU(100, recurrent_dropout=0.1, kernel_initializer=\"glorot_uniform\", recurrent_activation='tanh'),\n",
    "                                name='ctx_bilstm')(ctx_embed)\n",
    "ctx_dropout = Dropout(0.2)(ctx_lstm)\n",
    "\n",
    "# define layers for topic-word\n",
    "lda_input_ctx = Input(shape=(config.seq_max_len,), dtype='int32', name='ctx_lda_input')\n",
    "lda_embed_ctx = lda_ctx_embed(lda_input_ctx)\n",
    "lda_embed_norm_ctx = BatchNormalization()(lda_embed_ctx)\n",
    "lda_lstm_ctx = Bidirectional(GRU(20, recurrent_dropout=0.1, kernel_initializer=\"glorot_uniform\", recurrent_activation='tanh'),\n",
    "                                name='lda_bilstm_ctx')(lda_embed_norm_ctx)\n",
    "lda_dropout_ctx = Dropout(0.2)(lda_lstm_ctx)\n",
    "\n",
    "merged_vector_ctx = keras.layers.concatenate([ctx_dropout, lda_dropout_ctx], axis=-1)\n",
    "merged_dense_ctx = Dense(100, activation='relu',\n",
    "                     kernel_initializer=\"glorot_uniform\", name='merged_dense_ctx')(merged_vector_ctx)\n",
    "\n",
    "\"\"\"\n",
    "Codes\n",
    "\"\"\"\n",
    "code_input = Input(shape=(10,), dtype='int32', name='code10_input')\n",
    "code_embed = code_embedding(code_input)\n",
    "code_lstm = Bidirectional(LSTM(lstm_num, dropout=dp_rate), name='code_lstm')(code_embed)\n",
    "\n",
    "\"\"\"Merge CTT and CTX\"\"\"\n",
    "final_merged = keras.layers.concatenate([merged_dense_ctx, merged_dense_ctt, code_lstm], axis=-1)\n",
    "last_drop = Dropout(0.1)(final_merged)\n",
    "predictions = Dense(3, activation='sigmoid', name='final_output')(last_drop)\n",
    "\n",
    "test_model = Model(inputs=[ctt_input, lda_input_ctt, ctx_input, lda_input_ctx, code_input], outputs=predictions)\n",
    "# official document shows RMSprop is a better choice for recurrent neural network\n",
    "test_model.compile(loss='categorical_crossentropy', optimizer= 'rmsprop',\n",
    "            metrics=['accuracy'])\n",
    "print(test_model.summary())\n",
    "\n",
    "hist = test_model.fit([x_train, ctt_lda_train, ctx_train, ctx_lda_train, prev10_train], code_train,\n",
    "            epochs=10,\n",
    "            batch_size=64,\n",
    "            validation_data=([x_valid, ctt_lda_valid, ctx_valid, ctx_lda_valid, prev10_valid], code_valid),\n",
    "            class_weight='auto')\n",
    "\n",
    "\n",
    "y_pred = test_model.predict([x_test, ctt_lda_test, ctx_test, ctx_lda_test, prev10_test]);print()\n",
    "report = classification_report([np.argmax(item) for item in y_pred], [np.argmax(item) for item in code_test])\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
